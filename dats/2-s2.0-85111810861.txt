Alzheimer's disease clinical trials need to demonstrate minimum clinically important differences
Deciding on the smallest change in an outcome that constitutes a clinically meaningful treatment effect, i.e. the minimum clinically important difference (MCID), is fundamental to interpreting clinical trial outcomes, making clinical decisions, and designing studies with sufficient statistical power to detect any such effect.
There is no consensus on MCIDs for outcomes in Alzheimer's disease (AD) trials, but the US Food and Drug Administration (FDA)'s consideration of aducanumab clinical trials data has exposed the uncertainty of the clinical meaning of statistically significant but small improvements.
Although MCIDs for outcomes, including Clinical Dementia Rating -Sum of Boxes (CDR-SB) and Mini-Mental State Examination (MMSE) in AD have been reported, the FDA guidelines, drafted in 1989 to facilitate regulatory approval of "substantially effective" antidementia drugs, do not specify quantified minimum differences.
While it is important that regulatory requirements encourage drug development and approval, without MCIDs, sponsors are motivated to power trials to detect statistical significance for only small and potentially inconsequential effects on clinical outcomes.
MCIDs benefit patients, family, caregivers and healthcare systems and should be incorporated into clinical trials and AD drug development guidance.

2
for outcomes, including Clinical Dementia Rating -Sum of Boxes (CDR-SB) and Mini-Mental State Examination (MMSE) in AD have been reported, the FDA guidelines, drafted in 1989 to facilitate regulatory approval of "substantially effective" antidementia drugs, do not specify quantified minimum differences.
While it is important that regulatory requirements encourage drug development and approval, without MCIDs, sponsors are motivated to power trials to detect statistical significance for only small and potentially inconsequential effects on clinical outcomes.
MCIDs benefit patients, family, caregivers and healthcare systems and should be incorporated into clinical trials and AD drug development guidance.

Main text:
Clinical trial outcomes for neuropsychiatric conditions, which form the basis for drug marketing decisions, are generally presented as quantitative differences between treatment groups on relevant symptom scales.
Deciding on the smallest change in an outcome that constitutes a clinically meaningful treatment effect, i.e. the minimum clinically important difference (MCID), is fundamental to interpreting trial outcomes, making clinical decisions, and designing studies with sufficient statistical power to detect such an effect.
This has become particularly important in the interpretation of data from drugs currently under investigation for treatment of dementia.
In this paper we ask if it is now time to include agreed MCIDs in the design, analysis and interpretation of Alzheimer's disease (AD) clinical trials?
Since the cholinesterase inhibitors (donepezil, rivastigmine, galantamine) and memantine obtained regulatory approval in the late 1990s and early 2000s, no further approved treatments for AD have materialized.
Recent excitement surrounding Biogen's Biologics License Application for aducanumab, an anti-amyloid antibody, has been dampened by uncertainty over its effectiveness and controversy over the US Food and Drug Administration's (FDA) and Biogen's interpretation of the clinical trials data
The FDA Peripheral and Central Nervous System Drugs Advisory Committee voted nearly unanimously on November 6, 2020 against approval (10 against with 1 abstention)
Nevertheless, the possibility that the FDA might reject this recommendation and approve aducanumab for marketing raises again the important question: how should we objectively define whether a dementia treatment is clinically effective?
The same FDA Advisory Committee addressed this issue in 1989 5 , recommending, in part, that a 3-point difference between drug and placebo groups on the 11-item Alzheimer's Disease-Cognitive Subscale (ADAS-Cog11) represented a clinically meaningful difference.
A statistically significant difference on a prespecified neuropsychological outcome alone, however, was considered insufficient to indicate that an intervention makes a clinically meaningful difference as the p-value is the likelihood that such a difference is attributable to random chance 6 .
The p-value itself is not a measure of effect size.
Indeed, any effect larger than no (i.e.
zero) effect can be demonstrated to be statistically significant with a large enough sample size 7 .
Yet, there remains no consensus or agreement on minimum clinically important differences (MCID)   for outcomes in AD trials.
The FDA has long considered a treatment for mild to moderate AD dementia (corresponding to stages 4 and 5 in their 2018 draft guidance 8 ) to be substantially effective if there is improvement on a 'core' symptom (e.g. a measure of cognition) and a global clinical measure (e.g. a clinician's judgement of change) or a functional measure (e.g.
activities of daily living)
For studies including mild cognitive impairment (MCI) patients, or stage 3 8 , the FDA requires only statistically significant change on a prespecified composite measure that includes cognition and daily function combined, as demonstration of substantial effectiveness.
Moreover, in 2013 the agency specifically recommended the Clinical Dementia Rating -Sum of Boxes (CDR-SB) 10 as a composite measure that had demonstrated validity and reliability for this purpose
No quantified minimum differences were specified, but the rationale is that such a composite measure serves as an indicator of change in both the 'core' or cognitive outcome, i.e., memory, orientation, judgment and problem solving, and in global or daily function, i.e., community affairs, home and hobbies, so that a treatment that delivers statistical significance on the CDR-SB as a pre-specified primary outcome is, by definition, clinically meaningful
The European Medicines Agency (EMA) has a similar approach
But, has this bar for effectiveness been set too low, and have theat bestmodest effects of existing treatments served to downgrade our expectations for future treatments?
The current Biologics License Application for aducanumab provides some insight.
Two identically designed and simultaneously executed trials were undertaken in early-stage AD (i.e., MCI and mild dementia due to AD) but were stopped early due to perceived futility before half the participants had an opportunity to complete the trials.
On post hoc analysis, the higher dose group of the EMERGE trial was judged to have shown statistically significant reduced decline at the 78-week endpoint, with the following differences between placebo and aducanumab groups favouring aducanumab: -0.39 points on the CDR-SB, 0.6 points on the Mini-Mental State Examination (MMSE), -1.4 points on the ADAS-Cog13, and 1.7 points on the Alzheimer's Disease Cooperative Study -Activities of Daily Living (ADCS-ADL-MCI)
The companion trial, ENGAGE, did not show statistical significance on any of the outcomes: 0.03 on the CDR-SB, -0.1 points on the MMSE, -0.59 points on the ADAS-Cog13 and 0.7 points on the ADCS-ADL-MCI 15 .
The negligible effects in ENGAGE clearly indicate no clinically meaningful effect for aducanumab.
The very small mean differences favoring aducanumab in EMERGE, however, raise the question of whether these statistically significant outcomes were clinically meaningful.
A recent study estimated the MCID for clinical outcomes using anchor-based (change in outcome linked to clinical opinion) and distribution-based (MCID calibration based on the variation across participants) approaches, stratified by severity of cognitive impairment
It found that MCIDs increased with disease severity.
For MCI and mild AD, differences of 0.98 and 1.63 points for CDR-SB and 1.26 and 2.32 points for MMSE represented clinically meaningful change.
Another study, also using anchor-based methodology that linked scores to clinicians' assessment of clinically meaningful change in cognitive, functional and behavioral domains, reported that the MCID for the ADAS-Cog11 in mild AD patients was 3 points 17 .
Meeting MCID thresholds, however, are not requisites for the FDA concluding that a trial shows substantial effectiveness or authorizing marketing approval
Notably, with the aducanumab trials, neither the CDR-SB difference at -0.39 nor the MMSE at 0.6 points reached MCID thresholds (Table
The FDA, however, per its own guidance, can consider a single positive well-controlled trial that is supported by 'confirmatory evidence' to be substantial evidence of effectiveness without considering mean difference or effect size 18 .
Applying this interpretation to the aducanumab trials created considerable controversy.
This was especially so given that the identical ENGAGE trial failed to show any statistically significant benefits over placebo, and, indeed, mean effects numerically favored placebo on the CDR-SB and MMSE.
The FDA's decision on approval is expected by June 7, 2021.
There is no gold-standard method for determining MCIDs, and each approach has limitations.
In anchor-based approaches, the external measure of change (or anchor) is usually subjective, and definitions of what constitutes meaningful change may differ between clinicians and patients or caregivers.
The MCIDs in Table
However, clinical trial outcomes are used to detect a treatment benefit, and the threshold for worsening may not equate to the threshold for improvement
Relatively larger changes may be interpreted as clinically important at the individual level, whereas relatively smaller changes may be considered important at the group level, so the application of MCIDs to group means might set the bar high.
The FDA supports anchor-based methods to establish what constitutes meaningful individual-level change, which defines a 'responder' in adjunctive analyses,
However, this is ineffectual if the clinically relevant response is undefined and clinical trials are not powered to detect this.
It is notable that neither Biogen's nor FDA's analyses of the aducanumab trials included response at the individual level.
Despite their limitations, MCIDs are important, and problems arise if we don't use them when considering potential AD treatments.
As "the smallest difference in score in the domain of interest which patients perceive as beneficial and which would mandate, in the absence of troublesome side effects and excessive cost, a change in the patient's management" 21 , the MCID is a model that attempts to evaluate whether the efficacy of a therapy reflects clinical effectiveness experienced by clinicians and patients in the real world.
To make informed decisions, physicians, patients and caregivers need to understand the benefits any treatment is likely to provide and the period over which the benefits may persist, and to weigh this knowledge against information about potential side effects and other risks.
Of course, clinicians will differ in how they make these decisions, but if aducanumab is approved, what could clinicians tell patients and caregivers about what they should expect based on the data from two conflicting trials?
For comparison, donepezil has shown modest benefits over placebo across several trials
On average, 10mg per day of donepezil for 24-26 weeks was associated with improvements of -2.67 points on ADAS-Cog, 1.05 points on MMSE, and -0.53 points on CDR-SB, compared to placebo.
Importantly, in terms of safety, donepezil is well-tolerated, whereas high dose aducanumab is associated with a 35% rate of potentially non-trivial brain oedema and 20% rate of brain microhemorrhages (compared to 2% and 7% in placebo, respectively)
This would have increased the risk of unblinding in the high dose aducanumab group, which would have subjected outcomes to reporting bias, particularly with caregiver-informed scales such as the ADCS-ADL-MCI and CDR-SB.
As the small effect sizes seen with aducanumab also apply to other amyloid-targeting agents trialed so far, it seems that amyloid reduction alone does not produce clinically meaningful improvements in cognition.
Indeed, a recent meta-analysis found that the cognitive effect of reducing amyloid levels by 0.1 standardized uptake value ratio units was an improvement of 0.03 points on the MMSE 24 .
While it is important that regulatory requirements encourage drug development and approval, an alternate view would be that regulatory requirements for effectiveness set at a low bar encourage sponsors to substantially increase sample sizes of trials in order to raise their chances of detecting statistical significance for small or inconsequential effects on clinical outcomes.
For example, the EMERGE and ENGAGE aducanumab trials were initially powered at 90% (or 10% β error) to detect a CDR-SB difference of -0.5 over 78 weeks with a planned sample of 1350, but this was increased to 1605 (and achieved 1638 and 1647) midway through the trials 15 as it appeared that statistically significant outcomes might not be obtained.
Thus, EMERGE achieved a smaller than expected -0.39 difference on the CDR-SB, which was statistically significant when the trial was stopped, while ENGAGE resulted in a 0.03 point CDR-SB difference slightly favoring placebo that could not have been made statistically significant favoring aducanumab by increasing the sample size.
For comparison, the MCID for CDR-SB for MCI and mild AD has been considered to be 0.98 and 1.63 points respectively (Table
Considerations related to the instruments' psychometric properties (i.e.
reliability, validity and responsiveness) are relevant when deciding to use MCIDs to judge the clinical meaningfulness of treatments.
For example, the MMSE may be prone to unstable interrater reliability
Although composite outcomes, which aggregate cognitive and functional outcomes into a single summary score, are suggested to be more sensitive instruments for these early disease stages
These psychometric issues emphasise the contribution that MCIDs could offer in distinguishing between clinically meaningful changes and small changes in score due to measurement error.
As clinically meaningful change needs to be statistically reliable, methods to assess individual-level reliable change, e.g. using Reliable Change Index (RCI) methods
It is also important to account for the effect of baseline disease severity on MCIDs, which will influence trials' statistical power requirements.
It is clear that regulatory approval decisions made primarily on the basis of statistically significant differences in cognitive composite and global outcomes from AD dementia trials are unsatisfactory.
The FDA's 'dual' outcome criteria approach (i.e.
requiring statistical significance on both 'core' and global or functional measures) to determine the substantial effectiveness of antidementia drugs originated from the first FDA draft guidelines in 1989 9 to facilitate a pathway for regulatory approval, in response to pharmaceutical industry concerns about a lack of regulatory guidance.
The criteria were intended to provide "the lowest standard a sponsor must achieve" to establish effectiveness; but three decades on, the aducanumab data has re-exposed the uncertainty of clinical outcomes and the clinical meaning of statistically significant but small improvements.
We need to strike a better balance between regulators, sponsors, and patients' needs to achieve a common goal.
Clinical trials for cognitive impairment should be appropriately powered to reflect clinically meaningful differences in outcomes.
Drug development guidance for AD needs to incorporate definitions of clinically meaningful responses for at least the CDR-SB and MMSE, and studies of treatments should determine and report the MCID for other trial outcomes 31 and functional measures such as the ADCS-ADL-MCI.
The use of MCIDs would increase the clarity of and confidence in the outcomes of Alzheimer trials, substantially benefiting patients, family, caregivers and healthcare systems.
AUTHORS' CONTRIBUTIONS R.H. discussed the initial idea with K.L. and L.S. to develop the concept.
K.L. wrote the initial draft, under supervision from R.H, which she revised after receiving comments and edits from L.S. and R.H.

CONFLICTS OF INTERESTS
Outside the submitted work, L.S. reports grants and personal fees from Eli Lilly, Merck, and Roche/Genentech; personal fees from Boehringer Ingelheim, Neurim, Ltd, Neuronix, Ltd, Cognition, Eisai, Takeda, vTv, IBC, Abbot, and Samus; and grants from Biogen, Novartis, Biohaven, and Washington Univ/ NIA DIAN-TU.

Study AD population

Endpoint (weeks)

CDR-SB MMSE ADAS-Cog11

ADAS-Cog13

ADAS-Cog14
MCID   an intervention makes a clinically meaningful difference as the p-value is the likelihood that such a difference is not attributable to random chance (Wasserstein and Lazar 2016).
The p-value itself is not a measure of effect size.
Indeed, any effect larger than no (i.e.
zero) effect can be demonstrated to be statistically significant with a large enough sample size 6 .
Yet, there remains no consensus or agreement on minimum clinically important differences (MCID) for outcomes in AD trials.
The FDA has long considered a treatment for mild to moderate AD dementia (corresponding to stages 4 and 5 in their 2018 draft guidance 7 ) to be substantially effective if there is improvement on a 'core' symptom (e.g. a measure of cognition) and a global clinical measure (e.g. a clinician's judgement of change) or a functional measure (e.g.
activities of daily living)
For studies including early-stage patients (i.e., mild cognitive impairment (MCI) and mild dementia patients, or stages 3 and 4) 7 , the FDA requires only statistically significant change on a pre-specified composite measure that includes cognition and daily function combined, as demonstration of substantial effectiveness.
Moreover, in 2013 the agency specifically recommended the Clinical Dementia Rating -Sum of Boxes (CDR-SB) 9 as a composite measure that had demonstrated validity and reliability for this purpose
No quantified minimum differences were specified, but the rationale is that such a composite measure serves as an indicator of change in both the 'core' or cognitive outcome, i.e., memory, orientation, judgment and problem solving, and in global or daily function, i.e., community affairs, home and hobbies, so that a treatment that delivers statistical significance on the CDR-SB as a pre-specified primary outcome is, by definition, clinically meaningful 8 12 .
The European Medicines Agency (EMA) has a similar approach
But, has this bar for effectiveness been set too low, and have theat bestmodest effects of existing treatments served to downgrade our expectations for future treatments?
The current Biologics License Application for aducanumab provides some insight.
Two identically designed and simultaneously executed trials were undertaken in early-stage AD (i.e., MCI and mild dementia due to AD) but were stopped early due to perceived futility before half the participants had an opportunity to complete the trials.
On post hoc analysis, the higher dose group of the EMERGE trial was judged to have shown nominally statistically significant reduced decline at the 78-week endpoint, with the following differences between placebo and aducanumab groups favouring aducanumab: -0. with caregiver-informed scales such as the ADCS-ADL-MCI and CDR-SB.
As the small effect sizes seen with aducanumab also apply to other amyloid-targeting agents trialed so far, it seems that amyloid reduction alone does not produce clinically meaningful improvements in cognition.
Indeed, a recent meta-analysis found that the cognitive effect of reducing amyloid levels by 0.1 standardized uptake value ratio units was an improvement of 0.03 points on the MMSE 21 .
While it is important that regulatory requirements encourage drug development and approval, an alternate view would be that regulatory requirements for effectiveness set at a low bar encourage sponsors to substantially increase sample sizes of trials in order to raise their chances of detecting statistical significance for small or inconsequential trivial effects on clinical outcomes.
For example, the EMERGE and ENGAGE aducanumab trials were initially powered at 90% (or 10% β error) to detect a CDR-SB difference of -0.5 over 78 weeks with a planned sample of 1350, but this was increased to 1605 (and achieved 1638 and 1647) midway through the trials (FDA 2020) as it appeared that statistically significant outcomes might not be obtained.
Thus, EMERGE achieved a smaller than expected -0.39 difference on the CDR-SB, which was nominally statistically significant when the trial was stopped, while ENGAGE resulted in a 0.03 point CDR-SB difference slightly favoring placebo that could not have been made statistically significant favoring aducanumab by increasing the sample size.
For comparison, the MCID for CDR-SB for MCI and mild AD has been considered to be 0.98 and 1.63 points respectively over one year ( It is clear that Should we be satisfied with regulatory approval decisions made primarily on the basis of statistically significant differences in cognitive composite and global outcomes from AD dementia trials are unsatisfactory.
, even if those effects are not clinically meaningful?
The FDA's 'dual' outcome criteria approach (i.e.
requiring statistical significance on both 'core' and global or functional measures) to determine the substantial effectiveness of antidementia drugs originated from the first FDA draft guidelines in 1989 8 to facilitate a pathway for regulatory approval, in response to pharmaceutical industry concerns about a lack of regulatory guidance.
The criteria were intended to provide "the lowest standard a sponsor must achieve" to establish effectiveness; but three decades on, the aducanumab data has re-exposed the uncertainty of clinical outcomes and the clinical meaning of nominally statistically significant but small improvements.
We need to strike a better balance between regulators, sponsors, and patients' needs to achieve a common goal.
Clinical trials for cognitive impairment should be appropriately powered to reflect clinically meaningful , and not trivial differences in outcomes.
Drug  We thank the Reviewer for their helpful comments.
We agree that there are instrument-related issues related to MCIDs, which would be important to mention in the article.
We have now discussed these issues, along with the potential benefit of reliable change indices, in more detail in a new paragraph on Page 9 (below).

6, 9, 10
Reply to Reviewers Comments addition to statistically significant changes is very urgent, in RCTs in general but especially for the field of dementia trials.
I have some general comments that the authors may want to address in a revised version of their statement:
The question how we define whether a dementia treatment is clinically effective is highly important, and I fully support the authors' statement that only a statistically significant improvement (or difference with control arm) is insufficient or a treatment to be considered effective.
However, the notion of a 'clinically meaningful difference' based on just a specific instrument or rating scale (eg a 3point difference on the ADAS-Cog) is also arbritary in nature, as effects may not be linear (as stated in the manuscript), that is, potential benefits may differ for patients in the early stages of AD (incl MCI) compared to later stages of AD.
Also, the MCID should have good criterion validity, not just face validity (ie expert opinion).
That is how large does the difference on (say) the ADAS-Cog have to be, in order to reflect a *meaningful* change in everyday memory performance (eg not forgetting appointments, or remembering to check one's agenda)?
What also should be taken into account are the psychometric properties of the outcome scale, which is often ignored in the RCT field.
A lot of effort is often put into the trial analysis part and the trial's statistical power, a field that is dominated by biostatisticians.
We also thank the Reviewer for drawing our attention to the relevant references, which we now cite in the article.
We note that the McDougall paper on the psychometric limitations of the ADAS-Cog (and MMSE) was specific to prodromal AD, and although Dowling et al. found  We accept that the ADAS-Cog is unlikely to fully align with a person's functional status in AD.
As a specific instrument for measuring cognition, we have described in the article how the ADAS-Cog fulfils a requirement set by regulators, such as the FDA, to provide a measure of change in a 'core' AD symptom, i.e. cognition, alongside change in at least another measure of function or a global clinical measure (or both in a composite measure).
It is therefore equally valid to ask how large the difference on a functional measure (such as ADCS-ADL-MCI) needs to be to reflect a meaningful clinical change in function.
We have focused on MCID data for ADAS-Cog, MMSE the use of group statistics (ie, a statistically significant difference between two arms and an overall effect size for such an analysis).
However, measures of individual change are far more relevant as an outcome measure, e.g. the use of reliable change index (RCI) analyses, which also take psychometric limitations of a given outcome scale into account.
I would argue that the use of group statistics in RCTs alone (even including effect sizes expressing the overall magnitude that may even reflect an MCID) is insufficient, but that analyses of individual change are essential too (in the end, a treatment should benefit individual patients as well), but --as far as I know-not part of routine RCTs or evaluation agencies.
In my opinion, MCID should always incorporate some type of responder analysis.
and CDR-SB because values have been published, but MCIDs for functional outcomes, as raised by the Reviewer, are also important to interpret clinical trial outcomes.
We now include this recommendation in the last paragraph on Page 10: "...studies of treatments should determine and report the MCID for other outcomes 22 and functional measures such as the ADCS-ADL-MCI."
We have also expanded on the limitations of MCIDs and distinguish more clearly between group and individual level MCIDs on Page 6.

Reviewer #2:
This manuscript addresses an important issue that is particularly pertinent in the context of recent results in AD clinical trials.
Approaches to establishing the clinical meaningfulness of a treatment effect in AD, and on the CDR-SB in particular, are not well established and deserve further attention.
While the authors propose applying MCIDs to the delta between mean changes in treatment groups, some of the methods described (e.g. the anchor based methods) are more commonly used for individual level change.
As the authors state, the FDA does not supply MCIDs in their AD guidance but the FDA's draft Patient Focused Drug Development guidances/workshop documents express a We thank the Reviewer for their helpful comments and discussion on this issue.
We have now distinguished more clearly between individual-level and group-level MCID, and refer to the FDA PFDD guidance on Page 6.
We also describe some limitations of the MCID, including that applying them to group means that this may represent the setting of a high bar for efficacy.
"Relatively larger changes may be interpreted as clinically important at the individual level, whereas relatively smaller changes may be considered important at the group level, so the application of MCIDs to group means might set the efficacy bar clear preference for application of meaningful change thresholds at the individual level in order to compare the proportion of patients with a meaningful improvement/deterioration. Such supportive analyses are viewed as useful in contextualising the clinical meaningfulness of a continuous primary endpoint.
This approach is consistent with previous presentations/guidances for example the PRO guidance (2009), the principles of which, the FDA have stated, apply to all types of COAs.
The application of MCIDs to between group deltas typically sets a very high bar.
Based on the mean decline in the ENGAGE and EMERGE pbo groups, and the stated .98
MCID on the CDR-SB, there would need to be a 63% and 56% reduction in decline in Aducanumab arms to deem it clinically meaningful.This seems to be overwhelming efficacy rather than a threshold for clinical meaningfulness.
Based on the above, I do not agree with the authors' proposed approach to using MCIDs, but do agree that something more than statistical significance is needed.

Specific suggestions:
• Add detail on the various ways MCIDs can be calculated and used.
Coon and Cappelleri (2016,  Therapeutic Innovation & Reg Science, 50, 1,22-29) provide a useful summary.
We are grateful for the Reviewer's specific suggestions.
In the last paragraph on Page 5, we referred to "anchor-based (change in outcome linked to clinical opinion) and distribution-based (MCID calibration based on the variation across participants) approaches".
We have now cited the • With reference to the comment that FDA are supportive of the CDR-SB as a primary endpoint -I
In the last paragraph on Page 4, we stated that "For studies including mild cognitive impairment (MCI) patients, or stage 3 7 , the FDA requires only statistically think it is worth noting that their 2018 guidance encourages the development of novel endpoints for stage 3, suggesting that they are not entirely satisfied with the options available.
significant change on a pre-specified composite measure that includes cognition and daily function combined, as demonstration of substantial effectiveness."
The FDA 2018 guidance "encourages the development of novel approaches to the integrated evaluation of subtle functional deficits arising from early cognitive impairment".
We have now added a sentence referring to the composite outcomes on Page 9: "Although composite outcomes, which aggregate cognitive and functional outcomes into a single summary score, are proposed to be more sensitive instruments for these early disease stages (Vellas  et al. 2015; FDA: Draft Guidance For Industry On A...; EMA 2018), the evidence for their superiority over single test/domain measures is unclear (Schneider and Goldberg 2020)."
• I think this manuscript is incomplete without a discussion of using anchor based methods to determine thresholds for individual change given that FDA promote their use elsewhere.
I would also encourage the authors to consider discussing other approaches to determining clinical meaningfulness, e.g. would it be sufficient to show that a statistically significant CDR-SB translates to a large proportion of patients retaining ADLs on a secondary outcome?
The discussion on anchor-based methods for individual level change with reference to the FDA guidance is addressed in a previous comment above.
The question of whether a statistically significant but sub-MCID change in CDR-SB, combined with a large and significant change on a secondary and functional outcome, would represent clinical meaningfulness is relevant.
We consider that MCIDs for individual outcomes are needed to make clear conclusions about the treatment effect in trials.
For example, for aducanumab, the higher rate of adverse outcomes would be associated with a higher risk of unblinding.
As the ADL scale is rated by or in consultation with a caregiver, it is possible that this scale is more susceptible to the effects of unblinding compared to a more objective cognitive test completed with the patient alone.
We have now added on Page 8, "This would have increased the risk of unblinding in the aducanumab group, which may have subjected outcomes to reporting bias, particularly with caregiver-informed scales such as the ADCS-ADL-MCI and CDR-SB."
• The authors make a number of statements regarding the size of the Aducanumab delta either directly or indirectly, e.g.: ○ "The very small mean differences favoring aducanumab in EMERGE,however, raise the question of whether these nominally, statistically significant outcomes were clinically meaningful."
○ "Clinical trials for cognitive impairment should be appropriately powered to reflect clinically meaningful, and not trivial differences in outcomes"
While I think it absolutely appropriate to question the meaningfulness of these treatment effects, I would stop short of labelling them as nominal or trivial.
If the 22% reduction is believed, it would take patients in the Aducanumb group approx 23 months to reach the mean decline that was reached by the pbo group at 18 months.
This 5
We have now removed the words "nominal" and "trivial" from these and similar sentences.
Throughout month delay may or may not be considered of consequence by the community.

Reviewer #3:
The article by Liu et.
al. argued the importance of demonstrating minimum clinically importance difference (MCID) in the Alzheimer's disease (AD) clinical trials.
This is a well thought-out article -the controversy surrounding Biogen's anti-amyloid agent Aducanumab for the treatment of AD has been widely discussed recently.
The authors addressed the issue from clinicians' and patients' perspectives and pointed out why the demonstration of MCID is essential in patient care and decision making.
This is a welcoming view as the authors raised an important but often neglected issue: a statistical significance does not necessarily imply a clinical significance.
Indeed, a p-value of <0.05 alone is not enough to judge the effectiveness of an intervention vs. its comparator, and so the effect size should also be considered.
Some minor points: 1.
The authors compared the data from ENGAGE and EMERGE trials, which were based on 78 weeks of followup time to the MCIDs estimated from the Andrews' study, which was derived over a 1-year study period.
Please comment on if it is necessary to calibrate the MCIDs values from 1-year to 78-week study period for the comparison.
We thank the Reviewer for their helpful comments.
Please see response to Comment 1 above.
We have now removed these data for the MCID values because they were confusing and were not relevant to the Column 'Study Endpoint'.
Table
Table
be 'p>0.05'
for not statistically significant?
We have now changed this to p>0.05 as suggested.
Table
Financial relationships are easily identifiable, but conflicts can also occur because of personal relationships, academic competition, or intellectual passion.
A conflict can be actual or potential, and full disclosure to The Editor is the safest course.
Failure to disclose conflicts might lead to publication of an Erratum or even to retraction.
All submissions to The Lancet Psychiatry must include disclosure of all relationships that could be viewed as presenting a potential conflict of interest (see Lancet 2001; 358: 854-56 and Lancet 2003; 361: 8-9).
The Editor may use such information as a basis for editorial decisions, and will publish such disclosures if they are believed to be important to readers in judging the manuscript.
At the end of the text, under a subheading "Declaration of interest", all authors must disclose any financial and personal relationships with other people or organisations that could inappropriately influence (bias) their work.
Examples of financial conflicts include employment, consultancies, stock ownership, honoraria, paid expert testimony, patents or patent applications, and travel grants, all within 3 years of beginning the work submitted.
If there are no conflicts of interest, authors should state that none exist ("We declare no competing interests.").
Authors should be referred to by their initials in this section.
The statement should match the information on the supplied ICMJE forms.
Yes For Comments, Personal Views, and Reviews, The Lancet Psychiatry will not usually publish if an author, within the past 3 years, and with a relevant company or competitor, has any stocks or shares, equity, a contract of employment, or a named position on a company board; or has been asked by any organisation other than The Lancet Psychiatry, be named on, or to submit the paper (see Lancet 2004; 363: 2-3).
 Author affiliations and qualifications Please format the author affiliation list to Lancet style.
Please list authors by full first name and last name.
Then for affiliations, please list each institution (department, institute, city, state, country) with the author initial and full last name, followed by one degree, in brackets following the author institution.
Please indicate any full professors.
Please provide full institutional correspondence address for corresponding author.
Yes  Acknowledgments
We need written confirmation, including a signature, from everyone who is mentioned in the Acknowledgments section to confirm that they are happy to be quoted in your paper.
The following format can be used: "I permit <corresponding author> et al to list my name in the acknowledgments section of their manuscript and I have seen a copy of the paper <full article title>" NA  Role of medical writer or editor NA Was a medical writer or editor involved in the creation of your manuscript?
If yes, we need a signed statement from the corresponding author to include the name and information on funding of this person.
This information should be added to the Acknowledgment section.
In addition, you will need to send us a signed statement from this person declaring that he or she has given you permission to name him or her in the Acknowledgment section.
 Personal communication NA For each personal communication, please provide a letter confirming that the person agrees to their name being used.
Signed paper originals are required.
The following format can be used: "I permit <corresponding author> et al to cite a personal communication from me in their manuscript <full article title>"  Appendix NA It is not Lancet policy to edit or style supplementary material for the web; however, this material will be hosted on our website as a pdf conversion of the author-supplied Word file.
Please style your supplementary material as per the guidelines below.
Please note that we will be unable to correct any errors in the online appendix following publication; as such, please check carefully when submitting.
Please supply the appendix as a single Word file, with numbered pages.
Please do not include a cover page with details of the paper, as we add a cover page to the appendix file before publication with this information.


for neuropsychiatric conditions, which form the basis for drug marketing decisions, are generally presented as quantitative differences between treatment groups on relevant symptom scales.
Deciding on the smallest change in an outcome that constitutes a clinically meaningful treatment effect, i.e. the minimum clinically important difference (MCID), is fundamental to interpreting trial outcomes, making clinical decisions, and designing studies with sufficient statistical power to detect such an effect.
This has become particularly important in the interpretation of data from drugs currently under investigation for treatment of dementia.
In this paper we ask if it is now time to include agreed MCIDs in the design, analysis and interpretation of Alzheimer's disease (AD) clinical trials?
Since the cholinesterase inhibitors (donepezil, rivastigmine, galantamine) and memantine obtained regulatory approval in the late 1990s and early 2000s, no further approved treatments for ADAlzheimer's disease (AD) have materialized.
Recent excitement surrounding the Biogen's Biologics License Application for aducanumab, an anti-amyloid antibody, has been dampened by uncertainty over its effectiveness and controversy over the US Food and Drug Administration's (FDA) and Biogen's interpretation of the clinical trials data 1-3 .
The FDA Peripheral and Central Nervous System Drugs Advisory Committee voted nearly unanimously on November 6, 2020 against approval (10 against with 1 abstention) 4 .
Nevertheless, the possibility that the FDA might reject this recommendation and approve aducanumab for marketing raises again the important question: how should we objectively define whether a dementia treatment is clinically effective?
The same FDA Advisory Committee addressed this issue in 1989 5 , recommending, in part, that a 3-point difference between drug and placebo groups on the 11-item Alzheimer's Disease-Cognitive Subscale (ADAS-Cog11) represented a clinically meaningful difference.
A statistically significant difference on a prespecified neuropsychological outcome alone, however, was considered insufficient to indicate that


development guidance for AD needs to incorporate definitions of clinically meaningful responses for ,n MCIDs (at least for the CDR-SB and MMSE), and studies of treatments should determine and report the MCID for other trial outcomes 22 e.g.
ADAS-Cog13 and 14 and functional measures such as the ADCS-ADL-MCI.
The use of MCIDs would increase the clarity of and confidence in the outcomes of Alzheimer trials, substantially benefiting patients, family, caregivers and healthcare systems.


considered to have clinically important effects at the individual level if the proportion of responders is greater in the treatment versus the comparator group.
However, this is ineffectual if the clinically relevant response is undefined and clinical trials are not powered to detect this.
It is notable, that neither Biogen's nor the FDA's analyses of the aducanumab trials included response at the individual level."



Table 1 : Comparison of reported MCIDs and placebo-controlled outcomes for 10mg donepezil, high dose aducanumab, solanezumab and donanemab.
All the listed outcomes for ENGAGE and EXPEDITION 1-3 trials, and outcomes except for ADAS-Cog13 for TRAILBLAZER-ALZ, were not statistically significant (p>0.05).


definitions of what constitutes meaningful change may differ between clinicians and patients or caregivers.The MCIDs in Table1represent what constitutes a clinically meaningful decline, as patients' longitudinal change from baseline were anchored to clinicians' assessment of meaningful change(Andrews et al. 2019; Schrag   et al. 2012).However, clinical trial outcomes are used to detect a treatment benefit, and the threshold for worsening may not equate to the threshold for improvement(Coon and   Cappelleri 2016).Relatively larger changes may be interpreted as clinically important at the individual level, whereas relatively smaller changes may be considered important at the group level, so the application of MCIDs to group means might set the efficacy bar high.The FDA supports anchor-based methods to establish what constitutes meaningful As "the smallest difference in score in the domain of interest which patients perceive as beneficial and which would mandate, in the absence of troublesome side effects and excessive cost, a change in the patient's management" 18 , the MCID is a model that attempts to evaluate whether the efficacy of a therapy reflects clinical effectiveness experienced by clinicians and patients in the real world.To make informed decisions, physicians, patients and caregivers need to understand the benefits any treatment is likely to provide and the period over which the benefits may persist, and to weigh this knowledge against information about potential side effects and other risks.Of course, clinicians will differ in how they make these decisions, but if aducanumab is approved, what could clinicians tell patients and caregivers about what they should expect based on the data from two conflicting trials?For comparison, donepezil has shown modest benefits over placebo across several trials19,20.
On average, 10mg per day of donepezil for 24-26 weeks was associated with



Table 1 )
15.



Table 1 : Comparison of reported MCIDs and placebo-controlled outcomes for 10mg donepezil, high dose aducanumab, solanezumab and donanemab.



which form the basis for drug marketing decisions, are generally presented as quantitative differences between treatment groups on relevant symptom scales. Deciding on the smallest change in an outcome that constitutes a clinically meaningful treatment effect, i.e. the minimum clinically important difference (MCID), is fundamental to interpreting trial outcomes, making clinical decisions, and designing studies with sufficient statistical power to detect any such effect. This has become particularly important in the interpretation of data from drugs currently under investigation for treatment of dementia. In this paper we ask if it is now time to include agreed MCIDs in the design, analysis and interpretation of Alzheimer's disease (AD) clinical trials?"



Considerations related to the instruments' psychometric properties (i.e. reliability, validity and responsiveness) are relevant when deciding to use MCIDs to judge the clinical meaningfulness of treatments. For example, the MMSE may be prone to unstable inter-rater reliability (Nieuwenhuis- Mark 2010) and the ADAS-Cog has low sensitivity to detect change in MCI/prodromal AD (McDougall et al. 2021; Dowling et al. 2016), where relatively little longitudinal change will occur over the course of a trial as currently conducted. Although composite outcomes, which aggregate cognitive and functional outcomes into a single summary
that the ADAS-Cog had limited sensitivity to detect change in the study group overall, this was driven by the normal control and MCI subgroups and not the AD subgroup.
Nieuwenhuis-Mark reported good psychometric properties for the MMSE but had concerns about unstable inter-rater reliability, so we have focused on this specific property in our discussion of the MMSE.



are suggested to be more sensitive instruments for these early disease stages (Vellas et al. 2015; FDA: Draft Guidance For Industry On A...; EMA 2018), the evidence for their superiority over single test/domain measures is unclear (Schneider and Goldberg 2020). These psychometric issues emphasise the contribution that MCIDs could offer in distinguishing between clinically meaningful changes and small changes in score due to measurement error. As clinically meaningful change needs to be statistically reliable, methods to assess individual-level reliable change, e.g. using Reliable Change Index (RCI) methods (Jacobson and Truax 1991; Murray et al. 2021), may complement group and individual-level MCID approaches. It is also important to account for the effect of baseline disease severity on MCIDs, which will influence trials' statistical power requirements."



is no gold-standard method for determining MCIDs, and each approach has limitations. In anchor-based approaches, the external measure of change (or anchor) is usually subjective, and definitions of what constitutes meaningful change may differ between clinicians and patients or caregivers. The MCIDs in Table 1 represent what constitutes a clinically meaningful decline, as patients' longitudinal change from baseline were anchored to clinicians' assessment of meaningful change (Andrews et al. 2019; Schrag et al. 2012). However, clinical trial outcomes are used to detect a treatment benefit, and the threshold for worsening may not equate to the threshold for improvement (Coon and Cappelleri 2016)."
Coon andCappelleri paper and have included a statement that there is no "gold standard" method for determining the MCID, and have included a consideration of limitations related to this.


Required formatting of data in the appendix: o SI units are required, if appropriate o Numbers in text and tables should always be provided if % is shown.
o Means should be accompanied by SDs, and medians by interquartile range.
o Exact p values should be provided, unless p<0•0001 o For drug names, recommended international nomenclature (rINN) is required o References should be in Vancouver style (eg, Smith A, Jones, B, Clements S. Clinical transplantation of tissue-engineered airway.
Lancet 2008; 372: 1201-09.
Hourigan P. Ankle injuries.
In: Sports medicine.
Chan D, ed.
London: Elsevier, 2008: 230-47.)
They should be numbered in order of mention in appendix and numbered separately from references in the full paper o For figures in the appendix, all images must have a minimum resolution of 300 dpi at a width of 107 mm