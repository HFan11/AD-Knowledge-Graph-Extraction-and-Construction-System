Explicit and implicit memory for music in healthy older adults and patients with mild Alzheimerâ€™s disease
Introduction: Previous studies have found that music paired with lyrics at encoding may improve the memory performance of patients with mild Alzheimer's disease (AD).
To further explore memory for different types of musical stimuli, the current study examined both implicit and explicit memory for music with and without lyrics compared to spoken lyrics.
In this mixed design, patients with probable mild AD (n = 15) and healthy older adults (n = 13) listened to auditory clips (song, instrumental, or spoken lyrics varied across three sessions) and then had their memory tested.
Implicit memory was measured by the mere exposure effect.
Explicit recognition memory was measured using a confidence-judgment receiver operating characteristic (ROC) paradigm, which allowed examination of the separate contributions made by familiarity and recollection.
Results: A significant implicit memory mere exposure effect was found for both groups in the instrumental and song but not the spoken condition.
Both groups had the best explicit memory performance in the spoken condition, followed by song, and then instrumental conditions.
Healthy older adults demonstrated more recollection than patients with AD in the song and spoken conditions, but both groups performed similarly in the instrumental condition.
Patients with AD demonstrated more familiarity in the instrumental and song conditions than in the spoken condition.
The results have implications for memory interventions for patients with mild AD.
The implicit memory findings suggest that patients with AD may still show a preference for
Patients with AD often demonstrate relatively intact musical processing
Several case studies have found that components of musical memory are preserved in patients with AD (see
Prior work in our lab offered some of the first empirical evidence that musical mnemonics can be used as a memory enhancer in patients with Alzheimer's disease (Simmons-Stern,
In a subsequent test phase, patients with AD were more accurate in recognizing songs that had been presented with a sung recording than those presented with a spoken recording at encoding.
Several other studies have also provided evidence that musical mnemonics may be successful in enhancing memory performance in patients with AD
These studies suggest that patients with AD may have the potential to benefit from musical mnemonics, but to fully understand this potential, more information is needed about what types of memory for music are preserved in AD.
Explicit, episodic memory is the type of memory most impaired in patients with mild AD.
Remembering a list of words, pictures, or what was eaten for breakfast yesterday uses explicit memory, and this type of memory has been dissociated from implicit, or nonconscious, memory
Dual-process theories of explicit recognition memory describe two separate processes that can contribute to successful recognition memory: recollection and familiarity
Recollection is a rich, vivid, detailed memory for an item whereas familiarity is a more general sense of having encountered an item before without the associated specific context.
Recollection is severely impaired in patients with AD, so these patients are forced to rely more on familiarity, or gist, to make recognition memory judgments
While familiarity may not entirely be spared in patients with amnestic mild cognitive impairment (aMCI) and AD, it is better preserved than recollection
Relative sparing of familiarity's contribution to recognition memory may extend to musical stimuli.
In a series of experiments,
Six patients with AD were presented with songs paired with lyrics, instrumental music, and short stories repeated over 10 sessions.
In a subsequent memory test, the patients rated previously heard musical stimuli (both songs and instrumental) as more familiar than new musical stimuli, but this difference in familiarity ratings was not found for the short stories.
In a second experiment, Samson and colleagues demonstrated that memory for music was longer lasting than memory for poems in patients with AD.
Simmons-Stern et al. (
In the test phase, each participant was asked a general content question and then a specific content question about the lyrics they had heard in the encoding phase.
Healthy older adults and patients with AD performed better on the general content, or "gist," questions referring to the sung lyrics than on the questions referring to the spoken lyrics.
However, when it came to the recognition of specific lyric content, there was no difference in memory performance.
Similarly, an experiment using unfamiliar instrumental music clips indicated that while patients with aMCI demonstrated impaired recollection, their familiarity judgments were relatively intact, compared to healthy older adults
Collectively, these findings suggest that the mnemonic benefit of musical encoding may enhance the general content, or familiarity, of the lyrics, but this benefit may not extend to more specific information like that involved in recollection.
A receiver operating characteristic (ROC) paradigm can also be used to measure the separate contributions of recollection and familiarity to recognition memory performance (for a review, see
In the ROC paradigm, participants study items and then rate on a 6-point scale how certain they are that the test item is old or new.
These ratings allow for analysis of separate measures of recollection and familiarity.
Researchers have used the ROC paradigm to examine differences in recollection and familiarity in several patient groups including patients with medial temporal lobe damage
Though the ROC paradigm has been used to examine recollection and familiarity for words and pictures, to our knowledge, it has not yet been used with musical stimuli with these populations.
Applying the ROC paradigm in this context could provide valuable information for understanding memory for music in patients with AD.
Unlike explicit memory, implicit learning and memory may be preserved in severely amnesic patients
Implicit memory is measured by changes in performance due to prior experience that do not require deliberate retrieval of the original presentation, and it includes priming, habit learning, and procedural memory.
As such, implicit memory abilities have been used successfully in rehabilitation design with patients with memory disorders
One type of implicit memory is the mere exposure effect, which occurs when participants are more likely to prefer an item if it has been studied previously, regardless of conscious recollection
The mere exposure effect for musical stimuli has been found reliably in both young adults
The mere exposure effect has been found intact in patients with AD using unfamiliar visual stimuli
However, the two prior studies that have examined the mere exposure effect for music in patients with AD led to contradictory conclusions: One failed to demonstrate an effect
Both of these two studies used unfamiliar instrumental melodies without a comparison auditory condition to examined the mere exposure effect.
The current study investigates further into what types of memory for music are preserved in patients with mild AD.
In this study, we tested both implicit and explicit memory for three types of auditory stimuli: instrumental music (music without lyrics), song (instrumental music with lyrics), and spoken lyrics.
To examine the mere exposure effect, participants were asked to decide whether or not they liked previously heard versus new auditory stimuli.
Measuring this effect allowed us to evaluate the extent to which implicit memories for instrumental, song, and spoken stimuli are preserved in patients with mild AD.
To our knowledge, the current study will be the first examination of the mere exposure effect in patients with AD that compares different types of auditory stimuli.
We predicted that both healthy older adults and patients with AD would show the mere exposure effect for all auditory conditions.
To examine explicit recognition memory, we used an ROC paradigm in which we collected confidence ratings for memory recognition in place of dichotomous recognition memory judgments.
These confidence ratings were used to create ROC curves and compute separate measures of recollection and familiarity.
We predicted that healthy older adults would have higher rates of recollection than patients with AD for all conditions, but that patients with AD would show higher levels of familiarity for the song (instrumental plus lyrics) condition than for spoken or instrumental conditions.

Method Participants
Participants included 15 patients with mild probable AD (1 female) and 13 healthy older adults (OAs; 10 females).
Patients (Mini-Mental State Examination, MMSE, mean score = 23.53,
SD = 3.36) met criteria for probable AD identified by the National Institute on Aging-Alzheimer's Association
Healthy older adults were recruited from the spouses of patients with AD and community postings in the greater Boston area.
Participants were screened for clinically significant depression, alcohol or drug use, past stroke, traumatic brain injury, or other neurologic disorder.
All participants reported normal or corrected-to-normal hearing and vision.
Four additional participants were initially enrolled, but did not complete the experiment (two due to computer error, and two did not complete all three sessions).
The human subjects committee of the VA Boston Healthcare System and Boston University School of Medicine approved this study.
Formal written consent was obtained from all participants, and each participant was compensated $10/hour for their time.
All participants completed a brief neuropsychological test battery administered by trained personnel after the first session of this study or on a different day than their participation.
This battery began with the MMSE
Questions on the MMSE include orientation, learning and memory, attention, language, and visuospatial ability.
Scores greater than or equal to 24 are considered to be in the normal range.
In addition to the MMSE, all participants were also administered the Consortium to Establish a Registry for Alzheimer's Disease (CERAD) Word List Memory Test
Table
Groups did not differ on age (AD: M = 78.87,
SD = 8.25; OA: M = 79.69,
SD = 9.52), F(1, 26) = 0.23, p = .64,
or years of education (AD: M = 14.80,
SD = 3.36; OA: M = 15.58,
SD = 2.64), F(1, 25) = 0.85, p = .
37. Patients with AD scored significantly lower than OAs on the MMSE, t(15.71)
= 6.73, p < .001,
CERAD immediate recall, t(26) = 7.01, p < .001,
CERAD delayed recall, t(26) = 11.46,
p < .001,
CERAD recognition, t(14) = 4.80, p < .001,
Trail Making Test A, t(16.14)
= -3.62,
p = .002,
Trail Making Test B, t(16.38)
= -7.12,
p < .001,
letter fluency, t(26) = 5.08, p < .001,
semantic fluency, t(26) = 8.45, p < .001,
and short-form Boston Naming Test, t(14.61)
= 3.61, p = .003.

Stimuli
To create the stimuli for these experiments, we conducted a pilot study using an additional six healthy older adult participants (M age = 76.8).
We presented each participant with a clip (music + lyrics) from 78 contemporary artists and asked them to rate each clip on familiarity, lyric clarity, pleasantness, and likeability using a 5-point semantic differential scale.
To avoid prior associations or familiarity, we selected contemporary artists such as Death Cab for Cutie, Josh Ritter, and Sara Bareilles.
We used the pilot ratings to select 48 artists and then created six song excerpts from each of these 48 artists for the final stimuli (288 total clips, ranging from 7 to 18 s in length, typically including the chorus; length varied to include an entire musical phrase.
Song excerpts were selected so that a corresponding instrumental version (same section of music, but with no lyrics) could be sampled as well.
For the corresponding spoken recordings, we had 48 volunteers (same gender as original artist) read aloud the six sets of lyrics contained within the song clips.
Spoken recordings were created using Apple's Logic Pro 8 (Version 8.0.2;
Apple Inc.).
Readers were instructed to read slowly but naturally without conveying an emotional tone or emphasizing any rhyme in the lyrics.
In total, we created 864 audio recordings (288 full song, 288 instrumental music, and 288 spoken).
For counterbalancing purposes, we divided the 288 unique stimuli into six matched lists of 48 with one recording from each artist in each list.
All of the lists were matched on duration of song clip and number of words in lyrics as well as emotional valence, emotional arousal, clarity of lyrics, and lyric coherence, which were assessed by four young adult raters.
The lists were rotated through each experimental condition so that across participants each list appeared in each condition equally.

Procedure
Each participant completed three sessions (one per stimuli condition-instrumental, song, spoken) across three separate days, approximately one week apart.
During each session, data were collected for both implicit and explicit memory studies, following an identical format, with only differing content across conditions.
Sessions lasted approximately one hour, and the order of stimulus type (instrumental, song, spoken) was counterbalanced across participants.
The encoding phase of each session consisted of three parts.
In the first part of the encoding phase participants pressed a button corresponding to a like or dislike rating on 24 audio recordings presented via ATH-M30 Professional headphones by Audio-Technica.
During the second part of the encoding phase, we tested the mere exposure effect (implicit memory test).
The same 24 recordings were played again, randomly intermixed with 24 new recordings.
To the participants, the second part appeared to be a continuation of the first part (i.e., they seamlessly continued to make like/dislike ratings with no break).
In the third part of the encoding phase, the 24 new audio recordings were presented again in random order to ensure that each recording was judged twice overall.
Directly following the encoding phase, we informed participants that they would complete a memory test for the excerpts just heard (explicit recognition memory test).
Participants were presented with 48 old recordings and 48 new recordings, randomly intermixed.
Participants were asked to indicate their confidence that the excerpt was old or new on a 6-item semantic differential scale (1 = certain new, 2 = somewhat certain new, 3 = not at all certain new, 4 = not at all certain old, 5 = somewhat certain old, 6 = certain old).
We examined our data for session order effects, but the order of the sessions (instrumental vs. song vs. spoken first) was not a significant main effect and did not interact with any other variable of interest for any of our measures so is not included in the analyses reported.

Results

Implicit memory
To examine implicit memory performance, we calculated the percentage of items of each type that were liked in the implicit test phase [(number of new items liked/24) Ã— 100; (number of old items liked/24) Ã— 100].
We ran a 2 Ã— 2 Ã— 3 repeated measures analysis of variance (ANOVA) with a between-subjects factor of group (AD, OA) and within-subjects factors of item type (old, new) and condition (instrumental, song, spoken) to examine these liking rates (see Figure
There was a significant main effect of item type, F(1, 26) = 4.58, p = .04,
Î· 2 p = .15,
a significant main effect of condition, F(2, 52) = 4.08, p= .02,
Î· 2 p = .14,
and a significant interaction of Item Type Ã— Condition, F(2,52) = 4.43, p = .02,
Î· 2 p = .15.
Follow-up t-test comparisons indicated that for both the instrumental and song conditions, the old excerpts were significantly more liked (55% and 45%, respectively) than the new excerpts (47% and 35%, respectively) [instrumental: t(27) = -2.17,
p = .04;
song: t(27) = -3.46,
p = .002].
There was no difference between the new and old excerpts for the spoken condition (46% and 45%, respectively), t(27) = 0.89, p = .38.
Furthermore, follow-up t tests found that the old instrumental excerpts were preferred over old song excerpts, t(27) = 2.17, p = .04,
and over old spoken excerpts, t(27) = 2.32, p = .03.
There was no main effect of group, F(1, 26) = 0.27, p = .61,
and no interaction between item type and group, F(2, 52) = 0.15, p = .70,
or condition and group, F(2, 52) = 2.02, p = .14.

Explicit memory
To fully examine explicit memory performance, we analyzed (a) recollection (R), (b) familiarity (d f â€²), (c), recognition accuracy (Pr), and (d) response bias (Br).
Table
Through the use of ROC curves, we are able to calculate separate contributions of recollection and familiarity to recognition memory judgments by the calculation of estimates of R and d f â€².
We also examined overall recognition accuracy (Pr) and response bias (Br).
Higher recognition accuracy levels (Pr) indicate better discrimination between old and new items.
Finally, we wanted to examine response bias (Br), which measures the tendency to respond using either a more liberal (i.e., endorsing "old" frequently; Br > .5)
or conservative (i.e., endorsing "old" infrequently; Br < .5)
decision criterion.

Yonelinas high threshold (YHT) ROC curves
Consistent with previous studies
Responses of 6, 5, 4, 3, and 2 were used to calculate Yonelinas high threshold (YHT) parameter hit and falsealarm rates for old and new items.
To calculate YHT estimates of recollection and familiarity, it is assumed that all responses other than 1 ("certain new") reflect some level of recognition memory.
The ROC curve was created by plotting hit and false-alarmrates against each other at each confidence level.
The first, leftmost point on the curve reflects the hit and false-alarm rates for the 6 ("certain old") response, and the second point is hit and falsealarm rates for 5 and 6 responses as the curve reflects cumulative rates.
The Yonelinas Microsoft Excel solver routine was then used to generate separate recollection (R) and familiarity (d f â€²) estimates for each participant within each condition.
The solver estimates these parameters by fitting a nonlinear equation to each participant ROC by reducing the sum of squared errors between the predicted and observed data.
The recollection estimate (R) was calculated as the yintercept of the regression line whereas the familiarity estimate (d f â€²) was calculated based on the area under the curve (AUC).
Figure

Recollection (R) and familiarity (d f â€²)
Figure
Mauchly's test indicated that the assumption of sphericity had been violated for the main effect of condition on recollection, Ï‡ 2 (2) = 10.33,
p < .05,
as well as on familiarity, Ï‡ 2 (2) = 27.66,
p < .001.
Therefore, degrees of freedom were corrected using Greenhouse-Geisser estimates of sphericity (Ï‡ = .75
for main effect on recollection; Ï‡ = 0.60 for main effect on familiarity).
We ran a 2 Ã— 3 repeated measures ANOVA with a between-subjects factor of group (AD, OA) and a within-subjects factor of condition (instrumental, song, spoken) to examine the contribution of recollection (R).
There was a significant main effect of condition on recollection, F(1.5, 38.85) = 21.46,
p < .001,
Î· 2 p = .45.
A main effect of group indicated that OA participants demonstrated more recollection than AD patients, F(1, 26) = 9.91, p < .004,
Î· 2 p = .28.
However, there was a significant Group Ã— Condition interaction effect, F(2, 52) = 10.68,
p < .001,
Î· 2 p = .29.
Contrasts revealed that OA participants demonstrated significantly more recollection than AD participants for the song condition, F(1, 26) = 4.42, p = .045,
Î· 2 p = .15,
as well as for the spoken condition, F(1, 26) = 34.40,
p < .001,
Î· 2 p = .
57, but the groups demonstrated similar amounts of recollection memory for the instrumental condition, F(1, 26) = 0.44, p = .5,
Î· 2 p = .02.
We ran a 2 Ã— 3 repeated measures ANOVA with between-subjects factor of group (AD, OA) and within-subjects factor of condition (instrumental, song, spoken) to examine the contribution of familiarity (d f â€²).
A main effect of condition on familiarity was found, F(1.20, 31.15)
= 5.23, p = .02,
Î· 2 p = .17.
Follow-up t tests revealed that participants had higher familiarity estimates in the instrumental than in the spoken conditions, t(27) = -2.26,
p = .
03, r = .40,
and in the song than in the spoken conditions, t (27) = -2.30,
p = .02,
r = .40.
Participants demonstrated similar amounts of familiarity for both instrumental and song conditions, t(27) = -0.59,
p = .56.
Between-subjects group effects indicated that OA participants demonstrated more familiarity than AD patients, F(1, 26) = 8.57, p = .007,
Î· 2 p = .25.
There were significant differences between OA and AD participants for the instrumental condition, F(1, predicted and observed data.
The recollection estimate (R) 26) = 7.78, p = .01,
Î· 2 p = .23,
as well as for the song condition, F(1, 26) = 4.51, p = .04,
Î· 2 p = .15,
but no significant differences between the groups in the spoken condition, F(1, 26) = 3.50, p = .07.

Recognition accuracy
We calculated hit rate (HR) by summing participant confidence ratings of 4, 5, and 6-not at all certain old, somewhat certain old, certain old-on studied old items and dividing by number of old items.
Similarly, we calculated false-alarm rate (FAR) by summing participant confidence ratings of 4, 5, and 6 for new items and dividing by number of new items.
We calculated corrected recognition as hit rate minus false-alarm rate (Pr;
We then ran a 2 Ã— 3 repeated measures ANOVA with between-subjects factor of group (AD, OA) and within-subjects factor of condition (instrumental, song, spoken) to examine corrected recognition (Pr).
As expected, healthy older adults showed higher levels of recognition accuracy than patients with AD, F(1, 26) = 22.99, p < .001,
Î· 2 p = .47.
There was also a significant main effect of condition, F(2, 52) = 59.83, p < .001,
Î· 2 p = .70,
and a significant Group Ã— Condition interaction, F(2, 52) = 5.23, p = .009,
Î· 2 p = .17,
found for corrected recognition.
Follow-up t tests revealed that OA participants performed significantly worse on the instrumental condition than on both song, t(12) = -2.23,
p = .045,
and spoken conditions, t(12) = -11.55,
p < .001,
whereas AD patients showed similar memory performance for both instrumental and song conditions, t(14) = -1.11,
p = .29.
Patients with AD also showed worse corrected recognition performance for instrumental than for spoken, t(14) = -3.97,
p = .001,
and for song than for spoken conditions, t(14) = -4.41,
p = .001.

Response bias
Finally, we calculated response bias using Br [FAR/1 -(HR -FAR);
We ran a 2 Ã— 3 repeated measure ANOVA with between-subjects factor of group (AD, OA) and within-subjects factor of condition (instrumental, song, spoken) to examine response bias (Br; see Table
A significant main effect of condition for response bias was found, F(2, 52) = 3.56, p = .04,
Î· 2 p = .12.
There was no main effect of group; however, a significant interaction of Group Ã— Condition was found, F(2, 52) = 5.6954, p = .006,
Î· 2 p = .
18. Follow-up t tests found that AD patients showed a more liberal response bias for the spoken (mean Br = .47)
than for the song condition (mean Br = .30),
t(14) = -2.55,
p = .023,
whereas OA participants showed a more liberal response bias for the instrumental (mean Br = .49)
than for the song (mean Br = .34),
t(12) = 3.00, p = .01,
and spoken conditions (mean Br = .28),
t(12) = 2.97, p = .01;
there were no differences in OA participants' response bias between song and spoken conditions, t(12) = 0.77, p = .45.

Discussion
The current study examined implicit and explicit memory performance for instrumental, song, and spoken auditory stimuli in healthy older adults and patients with mild AD.
We observed the mere exposure effect in instrumental and song conditions but not in the spoken condition for both groups.
Interestingly, in the implicit mere exposure task, participants showed an effect for both musical conditions and not the spoken condition, but in the explicit recognition memory task, performance was better in both groups for the spoken condition than for the musical conditions.
The mere exposure effect is expressed as a preference for familiar stimuli over unfamiliar stimuli even in the absence of conscious memory.
In our experiment, both groups showed the mere exposure effect for the song and instrumental conditions but not for the spoken condition.
Importantly, we did not observe a group difference in this effect, offering evidence that this implicit memory function remains intact in patients with mild AD.
Mere exposure effects for musical stimuli have been demonstrated previously in young adults and healthy older adults, although sometimes a smaller mere exposure effect has been found for older adults
They found mere exposure effects present in these amnestic patients to be of a similar magnitude to that of a matched control group despite the patients' poor recognition memory, suggesting that, unlike recognition memory, the mere exposure effect is not dependent on the medial temporal lobe.
Since the effect is not dependent on explicit memory, the prediction would be that the mere exposure effect would be intact in patients with AD, but the literature is not straightforward.
The patients used in Halpern and O'Connor were more advanced in the disease progression (average MMSE = 20.2
out of 30) than participants in the current study, potentially leading to increased levels of neuropathology and cognitive impairment, although there has been some evidence that implicit effects may become more pronounced with disease severity (Klimkowicz-Mrowiec, Slowik, Krzywoszanski,
The results of the current study offer more evidence that the mere exposure effect is intact in both healthy older adults and patients with AD no matter what the stimulus modality is, although it is unclear why we did not find this effect for the spoken stimuli.
The mere exposure effect is most often examined using unfamiliar stimuli to avoid already established preferences.
Therefore, one explanation for our findings is potentially that the spoken condition was more impacted by prior preferences than the musical conditions.
Interestingly, the most preferred stimuli (ranked highest on the liking ratings) were the previously encountered instrumental stimuli despite resulting in the poorest performance in the explicit recognition test.
In the explicit memory test, both groups performed best in the spoken, then song, and then instrumental conditions.
Overall, healthy older adults performed better than patients with AD.
There was an interaction between condition and group with healthy older adults showing worse performance for instrumental than the other two conditions whereas patients with AD showed equally poor performance for song and instrumental conditions.
Both groups showed a more liberal response bias for the instrumental than for the song conditions.
There was also an interaction between group and stimulus condition with healthy older adults shifting to a more liberal response bias for the instrumental condition (the most difficult condition), whereas the patients with AD used a more liberal criterion for the spoken condition (the least difficult condition).
Surprisingly, patients with AD did not show a more liberal response bias overall than healthy older adults, which is contrary to typical findings in prior studies
However, in our prior work
In the current study, patients with AD also shifted to be more conservative for the musical conditions, and this may have resulted in the lack of an overall difference between groups.
To our knowledge, our experiment is one of the first to use the ROC procedure to examine the separate contributions of recollection and familiarity to recognition memory for musical stimuli in healthy older adults and patients with mild AD.
Healthy older adults demonstrated more recollection on both spoken and song conditions than patients with AD; however, the groups showed no difference in recollection estimates in the instrumental condition (although this lack of a difference could potentially be due to floor effects).
Healthy older adults also demonstrated more familiarity than patients with AD.
More familiarity was demonstrated in the instrumental and song condition than in the spoken condition.
Healthy older adults demonstrated more familiarity for the instrumental and song conditions, but had similar estimates for the spoken condition as patients with AD.
In general, patients with AD demonstrated very little recollection overall and more familiarity, supporting findings from previous studies showing that these patients heavily rely on familiarity (e.g.,
These findings suggest that there may be limitations on the benefits that music can provide to recognition memory performance by enhancing the contributions of recollection and familiarity.
One factor that may have influenced our findings is the complexity of the musical stimuli used.
Previous studies, including the work of
Our study used fully produced, complex music as one would hear on the radio, with many instruments playing at the same time, multiple melody lines combining in harmonies, and complex or syncopated rhythms.
The spoken condition had only two features: the lyrics and the voice of the speaker.
In the spoken condition, since there are fewer dimensions to monitor, this may have allowed participants to more easily encode and retrieve these stimuli in the explicit memory task.
Another possibility is that the musical excerpts shared a great deal of perceptual overlap.
To select music unfamiliar to most of the older participants, the majority of the songs selected fell into the indie/alternative genre.
Thus, the unfamiliar music used may have been too perceptually similar across stimuli for participants to discriminate without more repetition.
Repetition within and of musical stimuli may have the potential to alter memory performance as well as implicit preferences
Additionally, reducing the number of stimuli presented may have led to increased effects as memory performance would have been higher in both groups.
The current findings potentially suggest that music used in future clinical applications should either be already familiar to the individual or have a simple structure.
There are several important limitations to this study that suggest directions for future research.
Along with expanding the stimuli to include different genres of music, another important consideration is the emotionality of the music selected.
We worked to select stimuli that our participants would, in general, find pleasing, but it is possible that if we varied the emotion elicited by the music it could influence our results.
Healthy older adults often demonstrate a positivity effect, in which positive information is better remembered than negative information
This positivity effect might suggest that the use of musical stimuli eliciting a positive emotion might result in better memory performance.
Additionally, in this study we did not explicitly manipulate rhythmic complexity (although by choosing different pieces from the same musician we attempted to equate it), but future research could further explore the relationships between rhythm, neural entrainment, and memory
In the current study, we examined patients with mild AD, and potentially findings could be different if patients with aMCI were tested.
Also, some of our healthy older adult pool were made up of spouses of patients with AD, which might result in higher than normal levels of stress or other issues that might influence our findings.
In future studies, it would be informative to look at whether memory for types of music differs as a function of musical training.
In the current study, we did not collect information on musical expertise, but this could potentially influence the findings.
A recent study by
This study suggests that there may be important limitations to the relationship between music and memory performance, particularly in the context of memory impairment as seen with Alzheimer's disease.
The mere exposure effect was preserved in the patients with AD for the musical stimuli.
The findings suggest that simple exposure to a stimulus taps into memory networks and that patients with AD memory deficits may still demonstrate a preference for information familiar to them.
This knowledge could be used to help construct memory interventions; albeit, further work needs to be done to understand the nuances of this possible mechanism.
The explicit memory performance for both groups was best for the spoken condition, although the response bias findings provided further evidence that musical stimuli may result in a shift to a more conservative criterion for the patients with AD.
Potentially this finding could be leveraged in future strategies to improve memory performance by reducing false memories in these patients.
Although the problem in memory impairment is cognitive in nature, clinical music interventions could have broader reaching implications for those with AD.
Music is an inherently social and pleasurable experience over the course of a lifetime, sparking pleasant autobiographical memories even in individuals with more cognitive impairment
The current study examines the aspects of memory that may be unaffected by AD pathology using a music task; the findings may facilitate the development of both cognitive interventions and other nonpharmacological interventions aimed at impacting quality of life or emotional wellbeing in older adults with Alzheimer's.
As we build on our understanding of how music may boost memory performance for patients with AD, we will need studies that continue to investigate the relationship between music and memory in this population and translate the findings into potential clinical interventions that improve daily independent functioning for patients.
This study is one step in that direction, by beginning to outline what may and may not be efficacious in enhancing memory performance.
Future intervention studies should aim to determine the benefits and the limitations of the impact of music on memory performance, as well as the potential impact on quality of life or well-being in individuals with Alzheimer's disease.
Percentage of stimuli liked for each stimulus condition separated by item type for both participant groups.
The old versus new differences were significant for the song and instrumental conditions, though not for the spoken condition.
There was no effect of group.
Receiver operating characteristic (ROC) curve for participants with Alzheimer's disease (A; top) and for healthy older adults (B; bottom) in each experimental condition
This curve is created by plotting the cumulative hit rate by false-alarm rate at each criterion level.
For ROC curves, random guessing corresponds to the dotted diagonal line.
Recollection and familiarity for each experimental condition (instrumental, song, spoken) by group (healthy older adults, OA; participants with Alzheimer's disease, AD; specific values presented in Table
Familiarity (dâ€²f) is thought to measure the sense of experience ("This music sounds familiar") but without specific details.
Recollection (R) is thought to reflect a richer, more detailed memory for the excerpt ("I remember liking the melody of this song").


Figure 1.


Figure 2.


Figure 3.



Table 1 .
Demographics and neuropsychological test scores by group.



older adults (n = 13) M (SD) Patients with AD (n = 15) M (SD)
Note.
AD = Alzheimer's disease; MMSE = Mini Mental State Examination; CERAD = Consortium to Establish a Registry for Alzheimer's Disease; BNT = Boston Naming Test.