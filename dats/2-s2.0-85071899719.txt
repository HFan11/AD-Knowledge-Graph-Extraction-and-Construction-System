Alzheimer's Disease Neuroimaging Initiative-Based Evaluation Study
Longitudinal studies of development and disease in the human brain have motivated the acquisition of large neuroimaging data sets and the concomitant development of robust methodological and statistical tools for quantifying neurostructural changes.
Longitudinal-specific strategies for acquisition and processing have potentially significant benefits including more consistent estimates of intra-subject measurements while retaining predictive power.
Using the first phase of the Alzheimer's Disease Neuroimaging Initiative (ADNI-1) data, comprising over 600 subjects with multiple time points from baseline to 36 months, we evaluate the utility of longitudinal FreeSurfer and Advanced Normalization Tools (ANTs) surrogate thickness values in the context of a linear mixed-effects (LME) modeling strategy.
Specifically, we estimate the residual variability and between-subject variability associated with each processing stream as it is known from the statistical literature that minimizing the former while simultaneously maximizing the latter leads to greater scientific interpretability in terms of tighter confidence intervals in calculated mean trends, smaller prediction intervals, and narrower confidence intervals for determining cross-sectional effects.
This strategy is evaluated over the entire cortex, as defined by the Desikan-Killiany Tourville labeling protocol, where comparisons are made with the cross-sectional and longitudinal FreeSurfer processing streams.
Subsequent linear mixed effects modeling for identifying diagnostic groupings within the ADNI cohort is provided as supporting 1 Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (

INTRODUCTION
Quantification of brain morphology facilitates the investigation of a wide range of neurological conditions with structural correlates, including neurodegenerative conditions such as Alzheimer's disease
Essential for thickness quantification are the computational techniques which were developed to provide accurate measurements of the cerebral cortex.
These include various mesh-based (e.g.,
In inferring developmental processes, many studies employ cross-sectional population sampling strategies despite the potential for confounding effects
Large-scale studies involving longitudinal image acquisition of a targeted subject population, such as the Alzheimer's Disease Neuroimaging Initiative (ADNI)
Analogously, much research has been devoted to exploring methodologies for properly exploiting such studies and avoiding various forms of processing bias
For example, FSL's SIENA (Structural Image Evaluation, using Normalization, of Atrophy) framework
As the authors point out, "[i]n this way both images are subjected to a similar degree of interpolation-related blurring."
Consequences of this "interpolationrelated blurring" were formally analyzed in
These insights and others have since been used for making specific recommendations with respect to longitudinal image data processing
In
It has since been augmented by integrated linear mixed effects modeling capabilities
Although the FreeSurfer longitudinal processing stream isperhaps one of the most well-known, other important longitudinal-specific methodologies have been proposed for characterizing cortical morphological change.
Similar to Free Surfer, cortical surfaces are generated in
Application to early infants in
We introduced the Advanced Normalization Tools (ANTs) cortical thickness pipeline in
This proposed ANTs-based pipeline has since been directed at a variety of neuroimaging research topics including mild cognitive impairment and depression
Other authors have extended the general framework to non-human studies
In this work, we introduce the longitudinal version of the ANTs registration-based cortical thickness pipeline and demonstrate its utility on the publicly available ADNI-1 data set.
In addition, we demonstrate that certain longitudinal processing choices have significant impact on measurement quality in terms of residual and between-subject variances which is known to impact the scientific interpretability of results, produce tighter confidence intervals in calculated mean trends and smaller prediction intervals, as well as less varied confidence/ credible intervals for discerning cross-sectional effects.
This evaluation strategy goes beyond previously used precision-style assessment quantities which are limited in determining the actual clinical utility of cortical thickness as a longitudinal biomarker.

METHODS AND MATERIALS

ADNI-1 imaging data
The strict protocol design, large-scale recruitment, and public availability of the ADNI makes it an ideal data set for evaluating the ANTs longitudinal cortical thickness pipeline.
An MP-RAGE
Specific acquisition parameters for 1.5T and 3.0 T magnets are given in Table
As proposed, collection goals were 200 elderly cognitively normal subjects collected at 0, 6, 12, 24, and 36 months; 400 MCI subjects at risk for AD conversion at 0, 6, 12, 18, 24, and 36 months; and 200 AD subjects at 0, 6, 12, and 24 months.
The ADNI-1 data were downloaded in May of 2014 and first processed using the ANTs cross-sectional cortical thickness pipeline
Data was then processed using two variants of the ANTs longitudinal stream (described in the next section).
In the final set of csv files (which we have made publicly available in the GitHub repository associated with this work,
we only included time points for which clinical scores (e.g.,MMSE) were available.
In total, we included 197 cognitive normals, 324 LMCI subjects, and 142 AD subjects with one or more follow-up image acquisition appointments.

ANTs cortical thickness
Cross-sectional processing-A thorough discussion of the ANTs cross-sectional thickness estimation framework was previously provided in
As a brief review, given a T1-weighted brain MR image, processing comprises the following major steps (cf Fig.
Region-of-interest (ROI)-based quantification is achieved through joint label fusion
These data use the Desikan-Killiany-Tourville (DKT) labelling protocol
This pipeline has since been enhanced by the implementation
All spatial normalizations are generated using the well-known Symmetric Normalization (SyN) image registration algorithm
For evaluation, voxel wise regional thickness statistics were summarized based on the DKT parcellation scheme.
Test-retest error measurements were presented from a 20-cohort subset of both the OASIS (
Further evaluation employed a training/prediction paradigm where regional cortical thickness values generated from 1,205 images taken from four publicly available data sets (i.e., IXI (
The resulting regional statistics (including cortical thickness, surface area
These include the corresponding FreeSurfer measurements which are also publicly available for research inquiries (e.g.,
Since publication, this framework has been used in a number of studies (e.g.,
Unbiased longitudinal processing-Given certain practical limitations (e.g., subject recruitment and retainment), as mentioned earlier, many researchers employ cross-sectional acquisition and processing strategies for studying developmental phenomena.
Longitudinal studies, on the other hand, can significantly reduce inter-subject measurement variability.
The ANTs longitudinal cortical thickness pipeline extends the ANTs cortical thickness pipeline for longitudinal studies which takes into account various bias issues previously discussed in the literature
Given N time-point T1-weighted MR images (and, possibly, other modalities) and representative images to create a population-specific template and related images, the longitudinal pipeline consists of the following steps:

1.
(Offline): Creation of the group template and corresponding prior probability images.

2.
Creation of the unbiased single-subject template (SST).

3.
Application of the ANTs cross-sectional cortical thickness pipeline

4.
Creation of the SST prior probability maps.

5.
(Optional): Rigid transformation of each individual time point to the SST.

6.
Application of the ANTs cross-sectional cortical thickness pipeline
Input includes the SST and the corresponding spatial priors made in Step 3.

7.
Joint label fusion to determine the cortical ROIs for analysis.
An overview of these steps is provided in Fig.
ADNI group template, brain mask, and tissue priors.-Prior to any individual subject processing, the group template is constructed from representative population data
For the ADNI-1 processing described in this work, we created a population-specific template from 52 cognitively normal ADNI-1 subjects.
Corresponding brain and tissue prior probability maps for the cerebrospinal fluid (CSF), gray matter (GM), white matter (WM), deep gray matter, brain stem, and cerebellum were created as described in
A brief overview of this process is also provided in the section concerning creation of the single-subject template.
Canonical views of the ADNI-1 template and corresponding auxiliary images are given in Fig.
Single-subject template, brain mask, and tissue priors.-With the ADNI-1 group template and prior probability images, each subject undergoes identical processing.
First, an average shape and intensity SST is created from all time-point images using the same protocol
Next, six probabilistic tissue maps (CSF, GM, WM, deep gray matter (striatum + thalamus), brain stem, and cerebellum) are generated in the space of the SST.
This requires processing the SST through two parallel workflows.
First, the SST proceeds through the standard cross-sectional ANTs cortical thickness pipeline which generates a brain extraction mask and the CSF tissue probability map, P Seg (CSF).
Second, using a data set of 20 atlases from the OASIS data set that have been expertly annotated and made publicly available
Five of the JLF probabilistic tissue estimates (GM, WM, deep GM, brain stem, and cerebellum) and the JLF CSF estimate, P JLF (CSF), are used as the SST prior probabilities after smoothing with a Gaussian kernel (isotropic, σ = 1mm) whereas the CSF SST tissue probability is derived as a combination of the JLF and segmentation CSF estimates, i.e., P (CSF) = max (P Seg (CSF) , P JSF (CSF)),also smoothed with the same Gaussian kernel.
Finally, P (CSF) is subtracted out from the other five tissue probability maps.Note that the unique treatment of the CSF stems from the fact that the 20 expertly annotated atlases only label the ventricular CSF.
Since cortical segmentation accuracy depends on consideration of the external CSF, the above protocol permits such inclusion in the SST CSF prior probability map.
The final version of the SST and auxiliary images enable unbiased, nonlinear mappings to the group template, subject-specific tissue segmentations, and cortical thickness maps for each time point of the original longitudinal image series.
Individual time point processing.-The
first step for subject-wise processing involves creating the SST from all the time points for that individual
For the cross-sectional ANTs processing, the group template and auxiliary images are used to perform tasks such as individual brain extraction and n-tissue segmentation prior to cortical thickness estimation
However, in the longitudinal variant, the SST serves this purpose.
We thus deformably map the SST and its priors to the native space of each time point where individual-level segmentation and cortical thickness is estimated.
Note that this unbiased longitudinal pipeline is completely agnostic concerning ordering of the input time-point images, i.e., we "treat all time points exactly the same."
An ANTs implementation of the denoising algorithm described in
This denoising algorithm employs a non-local means filter
This preprocessing step has been used in a variety of imaging studies for enhancing segmentation-based protocols including hippocampal and ventricle segmentation
In the FreeSurfer longitudinal stream, each time-point image is processed using the FreeSurfer cross-sectional stream.
The resulting processed data from all time points is then used to create a mean, or median, single-subject template.
Following template creation, each time-point image is rigidly transformed to the template space where it undergoes further processing (e.g., white and pial surface deformation).This reorientation to the template space" further reduce[s] variability" and permits an "implicit vertex correspondence" across all time points
The ANTs framework also permits rotation of the individual time point image data to the SST, similar to FreeSurfer, for reducing variability, minimizing or eliminating possible orientation bias, and permitting a 4-D segmentation given that the Atropos segmentation implementation is dimensionality-agnostic
Regarding the 4-D brain segmentation, any possible benefit is potentially outweighed by the occurrence of "over-regularization"
Additionally, it is less than straightforward to accommodate irregular temporal sampling such as the acquisition schedule of the ADNI-1 protocol.
Registration-based cortical thickness.-The
underlying registration-based estimation of cortical thickness, Diffeomorphic Registration-based Estimation of Cortical Thickness (DiReCT), was introduced in
Given a probabilistic estimate of the cortical GM and WM, diffeomorphic-based image registration is used to register the WM probability map to the combined GM/WM probability map.
The resulting mapping defines the diffeomorphic path between a point on the GM/WM interface and the GM/CSF boundary.
Cortical thickness values are then assigned at each spatial location within the cortex by integrating along the diffeomorphic path starting at each GM/WM interface point and ending at the GM/CSF boundary.
A more detailed explanation is provided in
Joint label fusion and pseudo-geodesic for large cohort labeling.-Cortical
thickness ROI-based analyses are performed using joint label fusion
The brute force application of the joint label fusion algorithm would require N pairwise non-linear registrations for each time-point image where N is the number of atlases used.
This would require a significant computational cost for a relatively large study such as ADNI.
Instead, we use the "pseudo-geodesic" approach for mapping atlases to individual time point images (e.g.,
The transformations between the atlas and the group template are computed offline.
With that set of non-linear transforms, we are able to concatenate a set of existing transforms from each atlas through the group template, to the SST, and finally to each individual time point for estimating regional labels for each image.

Statistical analysis
Based on the above ANTs pipeline descriptions, there are three major variants for cortical thickness processing of longitudinal data.
We denote these alternatives as:
• ANTs Cross-sectional (or ANTs Cross).Process each subject's time point independently using the cross-sectional pipeline originally described in
• ANTs Longitudinal-SST (or ANTs SST).
Rigidly transform each subject to the SST and then segment and estimate cortical thickness in the space of the SST.
• ANTs Longitudinal-native (or ANTs Native).
Segment and estimate cortical thickness in the native space.
For completeness, we also include a comparison with both the cross-section and longitudinal FreeSurfer v5.3 streams, respectively denoted as "FreeSurfer Cross-sectional" (or "FS Cross") and "FreeSurfer Longitudinal" (or "FS Long").
Evaluation of cross-sectional and longitudinal pipelines-Possible evaluation strategies for cross-sectional methods have employed manual measurements in the histological
Other quantitative measures representing "reliability," "reproducibility," or, more generally, "precision" can also be used to characterize such tools.
For example,
In
However, none of these precision-type measurements, per se, indicate the utility of a pipeline-specific cortical thickness value as a potential biomarker.
For example, Figure
However, for the same data, the demographic predictive capabilities of the former was superior to that of the latter.
Thus, better assessment strategies are necessary for determining clinical utility.
For example, the intra-class correlation (ICC) coefficient used in
This is understood with the realization that the ICC takes into account both inter-observer and intra-observer variability.
Similarly, evaluation strategies for longitudinal studies have been proposed with resemblance to those employed for cross-sectional data such as the use of visual assessment
In addition, longitudinal methods offer potential for other types of assessments such as the use of simulated data (e.g.,atrophy
Longitudinal biomarkers and the use of linear mixed effects modelling-For a longitudinal biomarker to be effective at classifying subpopulations, it should have low residual variation and high between-subject variation.
Without these simultaneous conditions, subpopulation distinctions would not be possible (e.g., if measurements within the subject vary more than those between subjects).
A summary measure related to the ICC statistic
Specifically, we use linear mixed-effects (LME) modeling to quantify pipeline-specific between-subject and residual variabilities where comparative performance is determined by maximizing the ratio between the former and the latter.
Such a quantity implies greater within-subject reproducibility while distinguishing between patient sub-populations.
As such this amounts to higher precision when cortical thickness is used as a predictor variable or model covariate in statistical analyses upstream.
LME models comprise a well-established and widely used class of regression models designed to estimate cross-sectional and longitudinal linear associations between quantities while accounting for subject-specific trends.
As such, these models are useful for the analysis of longitudinally collected cohort data.
Indeed,
For more complete treatments of the subject matter, see
LME models are also useful for estimating and comparing residual and between-subject variability after conditioning out systematic time trends in longitudinally measured data.
In the context of the current investigation, by fitting LME models to the data resulting from cross-sectional and longitudinal processing techniques, we are able to quantify the relative performance of each approach with respect to residual, between-subject, and total variability in a way that
A variance ratio for assessing residual and between-subject cortical thickness variability-As previously noted, we observed a longitudinal sampling of cortical thickness measurements from the 62 parcellated cortical DKT regions.
To assess the above variabilitybased criteria while accounting for changes that may occur through the passage of time, we used a Bayesian LME model for parameter estimation.
Let Y ij k denote the i th individual's corti-cal thickness measurement corresponding to the k th region of interest at the time point indexed by j.
Under the Bayesian paradigm we utilized a model of the form
where specification of variance priors to half-Cauchy distributions reflects commonly accepted best practice in the context of hierarchical models
These priors concentrate mass near zero but have heavy tails, meaning small variance values are expected but large variance values are not prohibited.
Even so, results demonstrated robustness to parameter selection.
In Model (1), τ k represents the between-subject standard deviation, and σ k represents the within-subject standard deviation, conditional upon time, and β k i denotes the subjectspecific slopes of cortical thickness change.
For each region k, the quantity of interest is thus the ratio
The posterior distribution of r k was summarized via the posterior median where the posterior distributions were obtained using the Stan probabilistic programming language
The R interface to Stan was used to calculate the point estimates of Model (1) for cortical thickness across the different pipelines using the default parameters.
The csv files containing the regional cortical thickness values for all five pipelines, the Stan model file, and the R script to run the analysis and produce the plots are all located in the GitHub repository created for this work (
This ratio is at the heart of classical statistical discrimination methods as it features both in the ANOVA methodology and in Fisher's linear discriminant analysis.
These connections are important since the utility of cortical thickness as a biomarker lies in the ability to discriminate between patient sub-populations with respect to clinical outcomes.
In particular,
demonstrate the role that randomness and measurement error in explanatory variables play in statistical inference.
When the explanatory variable is fixed but measured with error (as is plausible for cortical thickness measurements), the residual variance divided by the between subject variance is proportional to the bias of the estimated linear coefficient when the outcome of interest is regressed over the explanatory variable (Example 9.2).
In short, the larger the r k , the less bias in statistical analyses.
When the explanatory variable is considered random and is measured with error (a common assumption in the measurement error literature
Thus, larger r k means less attenuation bias and hence more discriminative capacity.
Note that effect estimator bias is not the only problem-the residual variance is increased by a factor proportional to r k / 1 + r k ([67], Chapter 3).
The same authors refer to the combination of bias and added variance as a 'double whammy'.
Indeed, a worse reliability ratio causes greater bias in multiple linear regression in the presence of collinearity and even biases the estimators for other covariates, progression through time included (cf
The same authors state that this bias is typical even in generalized linear models (Section 3.6) and use the ratio as a measure of reliability even in the longitudinal context (Section 11.9).

Regional diagnostic contrasts based on cortical atrophy-
The variance ratio explored in the previous section is a desideratum for statistical assessment of performance over the set of possible use cases.
In this section, we narrow the focus to the unique demo graphical characteristics of the ADNI-1 study data and look at performance of the various pipelines in distinguishing between diagnostic groups on a region-by-region basis.
Previous work has explored various aspects of Alzheimer's disease with respect to its spatial distribution and the regional onset of.cerebral
atrophy.
For example, although much work points to the entorhinal cortex as the site for initial deposition of amyloid and tau
Other considerations include the use of hippocampal atrophy rates as an image-based biomarker of cognitive decline
Thus, longitudinal measurements have immediate application in Alzheimer's disease research.
To showcase the utility of the ANTs framework, we compare the generated longitudinal measurements and their ability to differentiate diagnostic groups (i.e., CN versus LMCI versus AD).
Pipeline-specific LME models were constructed for each DKT region relating the change in cortical thickness to diagnosis.
These regional LME models are defined as:
Here,ΔY ij k is the change in thickness of the k th DKT region from baseline (bl) thickness measurement Y bl k for the i th subject at the j th time point.
The subject-specific covariates (common to many ADNI-based studies) AGE, APOE status, GENDER, DIAGNOSIS, and VISIT were taken directly from the ADNIMERGE package.
α k i , γ s k , and ε k ij are independent, mean zero random variables representing individual-specific random intercepts, site-specific (indexed by s) random intercepts, and residual errors, respectively.
We also include random intercepts for both the individual subject (ID) and the acquisition site.
Modeling was performed in R using the lme4 package

RESULTS
All imaging data were processed through the five processing streams (i.e., FS Cross, FS Long, ANTs Cross, ANTs SST, and ANTs Native) on the high performance computing cluster at the University of California, Irvine (UCI).
Based on the evaluation design described in the previous section, we compare pipeline performance when applied to the ADNI-1 data.
Specifically, we calculate the variance ratios, described earlier, for each of the 62 DKT regions for each of the five pipelines.
These are compared and discussed.
We then explore how this general criterion for evaluating measurement quality applies specifically to a longitudinal analysis of the ADNI-1 data in discriminating the diagnostic stages of Alzheimer's disease.
After processing the image data through the various pipelines, we tabulated the regional thickness values and made them available as.csv files online in the corresonding GitHub repository (
Additional figures and plots have also been created which were not included in this work For example, spaghetti plots showing absolute thickness and longitudinal thickness changes are contained in the subdirectory CrossLong/Data/RegionalThicknessSpaghettiPlots/.

Cortical residual and between-subject thickness variability
The LME model defined in Equation (
Figure
Based on the discussion in the previous section, superior methododologies are designated by larger variance ratios.
ANTs SST has the highest ratio variance across most of the 62 regions over the other methods.
It rarely overlaps with ANTs Native and never with ANTs Cross.
In contrast to the majority of FreeSurfer regional ratio variances (from both FS Cross and FS Long) which are smaller than those of the ANTs pipelines, FS Long has larger ratio values for the EC region with the only overlap in the credible intervals with ANTs SST.
The plot in Fig.
These relative distributions show that both between-subject and residual quantities contribute to the disparities in the ratio evaluation metric.
Finally, we overlay the variance ratio values on the corresponding regions of a 3-D rendering of the ADNI template (Fig.

Regional diagnostic contrasts based on cortical atrophy
The LME model described in Equation (
It should be noted that no subjects were included that switched diagnostic groups during the acquired study schedule.
These findings are provided in Tables
The adjusted p-values were log-scaled for use in specifying the individual color cell for facilitating visual differentiation.
Each cell contains the corresponding 95% confidence intervals.
Figure
Consideration of performance over all three diagnostic pairings illustrates the superiority of the longitudinal ANTs methodologies over their ANTs cross-sectional counterpart.
Several regions demonstrating statistically significant non-zero atrophy in ANTs Native and ANTs SST do not mani-fest similar trends in ANTs Cross.
Pronounced differences between the ANTs longitudinal versus cross-sectional methodologies can be seen in both the LMCI-CN and AD-CN contrasts.
Although ANTs Cross demonstrates discriminative capabilities throughout the cortex and, specifically, in certain AD salient regions, such as the entorhinal and parahippocampal cortices, the contrast is not nearly as strong as the other methods including FS Cross and FS Long thus motivating the use of longitudinal considerations for processing of AD data.
Differentiation between the longitudinal methods is not as obvious although trends certainly exist.
In general, for differentiating CN versus LMCI, all methods are comparable except for ANTs Cross.
However, for the other two diagnostic contrasts AD-LMCI and AD-CN, the trend is similar to what we found in the evaluation via the variance ratio, viz., the longitudinal ANTs methods tend towards greater contrast means versus ANTs Cross and the two FreeSurfer methods.
Looking at specific cortical areas, though, we see that comparable regions("comparable" in terms of variance ratio)are consistent with previous findings.
For example, we noted in the last section that FSLong has a relatively large variance ratio in the entorhinal regions which is consistent with the results seen in Tables

DISCUSSION
Herein we detailed the ANTs registration-based longitudinal cortical thickness framework which is designed to take advantage of longitudinal data acquisition protocols.
This framework has been publicly available as open-source in the ANTs GitHub repository for some time.
It has been employed in various neuroimaging studies and this work constitutes a formalized exploration of performance for future reference.
It inherits the performance capabilities of the ANTs cross-sectional pipeline providing high reliability for large studies, robust registration and segmentation in human lifespan data, and accurate processing in data (human and animal) which exhibit large shape variation.
In addition, the ANTs longitudinal pipeline accounts for the various bias issues that have been associated with processing such data.
For example, denoising and N4 bias correction mitigate the effects of noise and intensity artifacts across scanners and visits.
The use of the single-subject template provides an unbiased subject-specific reference space and a consistent intermediate space for normalization between the group template and individual time points.
Undergirding all normalization components is the well-performing SyN registration algorithm which has demonstrated superior performance for a variety of neuroimaging applications (e.g.,
Also, given that the entire pipeline is image-based, conversion issues between surface-and voxel-based representations
All ANTs components are built from the Insight Toolkit which leverages the open-source developer community from academic and industrial institutions leading to a robust (e.g., low failure rate) software platform which can run on a variety of platforms.
With respect to these data and AD in general,the ANTs longitudinal cortical thickness pipelines use unbiased diffeomorphic registration to provide robust mapping of individual brains to group template space and, simultaneously, high-resolution sensitivity to subtle longitudinal changes over time.
Both advantages are relevant to AD. High baseline atrophy levels in AD lead to the need for robustness to large deformations.
Sensitivity to subtle longitudinal change over time is particularly relevant to early or preclinical AD studies due to the relatively reduced atrophy rates and smaller difference from control populations.
We demonstrate that our approach leads to competitive or superior estimates of annualized atrophy that are biologically plausible in AD populations and that may, in the future, support the use of T1 neuroimaging to detect treatment effects in clinical trials.
Furthermore, in ADNI-1, we report a zero percent failure rate with no subject-specific tuning required.
Over 600 subjects from the well-known longitudinal ADNI-1 data set with diagnoses distributed between cognitively normal, LMCI, and AD were processed through the original ANTs cross-sectional framework
One of the variants, ANTs SST, is similar to the FreeSurfer longitudinal stream in that each time-point image is reoriented to an unbiased single-subject template for subsequent processing.
ANTs Native, in contrast, estimates cortical thickness in the native space while also using tissue prior probabilities generated from the SST.
Comparative assessment utilized LME models to determine the between-subject to residual variance ratios over the 62 regions of the brain defined by the DKT parcellation scheme where higher values indicate greater generic statistical salience.
In these terms, ANTs SST outperformed all other pipeline variants including both the FreeSurfer longitudinal and cross-sectional streams.
Regional disparities between the ANTs SST and Native pipelines point to increases in both between-subject and residual variances which might be due to reorientation to a common space similar to other longitudinal strategies.
Further evidence motivating the longitudinal strategies proposed in this work and elsewhere stems from the subsequent exploration of differentiating between diagnostic groups using LMEs with the change in cortical thickness as an outcome variable.
Almost across the entire cortex, longitudinal strategies (both ANTs and FreeSurfer) outperformed their cross-sectional counterparts in pairwise differentiation of diagnostic groups although these trends varied based on region and diagnosis.
In the context of AD, where certain regions have increased saliency in terms of neuroscientific research, and practical considerations might give more weight to certain diagnostic results over others, further exploration is required to tease out these subtle differences and their implications for future research.
Furthermore, future studies, e.g., cross validation and prediction, will provide further understanding of performance characteristics.
One interesting finding was the performance of FS Long in the EC regions where the variance ratios was slightly larger than those of ANTs Long/Native where the credible intervals have significant over-lap.
Given the small volume and indistinguishability from surrounding structures, segmentation of the EC can be relatively difficult
This segmentation complexity has led to EC-specific
For this work, we wanted to avoid such tuning and simply employ off-the-shelf input parameters and data.
Future work will explore refining input template priors in these problematic regions for ANTs-based estimation of cortical thickness.
These findings promote longitudinal analysis considerations and motivates such techniques over cross-sectional methods for longitudinal data despite the increase in computational costs.
While we focus on cortical thickness in this work, there are obvious limitations with the ANTs volume-based frame-work.
Without a direct reconstruction of the cortical surfaces, many important cortical properties (e.g., surface area, cortical folding, sulcal depth, and gyrification)
Additional work will want to examine these features more closely working toward a more comprehensive idea of how structure changes.
This will help determine the relative importance of such cortical features and will undoubtedly guide future methodological development.
Finally, it should be noted that while the current findings certainly have utility, they are limited to a specific population and the community would benefit from replication and exploration in other populations.
However despite these deficiencies, being inherently voxel-based, the ANTs framework does have advantages not explored in this work but certainly to be utilized in future research.
Specifically, the voxel-based input/output processing is conducive to voxel-based analysis strategies (e.g., Eigenanatomy
Also, tensor-based morphometric data are directly extracted from the output of the longitudinal processing.
And while mesh-based geo-metric measures are unavailable, digital analogs (e.g., surface area from the digitized Crofton formula
Finally, given the importance of structural data, such as T1-weighted images, for other types of neuroimaging studies (e.g., resting state fMRI and diffusion tensor imaging), the longitudinal processing stream provides convenient output for facilitating these other types of analyses.
The ANTs longitudinal pipeline provides several additional features that may be worth investigation in future studies.
The segmentation approach provides tissue probability maps that may be used in identifying abnormalities of WM or in voxel-wise studies of GM density.
The longitudinal formulation of the pipeline is also likely to improve the variance ratio for other transformation based measurements such as the log-jacobian, often employed in tensor-based morphometry
Local folding and other curvature-based metrics are available, as well, through ANTsR
These quantification tools, individually or jointly, may provide insight into aging and neurodegeneration and will be the subject of future evaluation efforts.
The longitudinal thickness framework is available in script form within the ANTs software library along with the requisite processing components (Supplementary Material).
All generated data used for input, such as the ADNI template and tissue priors, are available upon request.
As previously mentioned, we also make available the csv files containing the regional thickness values for all three pipelines.
Native" in the text).
Optionally, one can rigidly transform the time-point images prior to segmentation and cortical thickness estimation (right column, red panel).
This alternative processing scheme is referred to as "ANTs SST".
For regional thickness values, regional labels are propagated to each image using a given atlas set (with cortical labels) and joint label fusion.
Top row: Canonical views of the template created from 52 randomly selected cognitively normal subjects of the ADNI-1 database.
The prior probability mask for the whole brain (middle row) and the six tissue priors (bottom row) are used to "seed" each single-subject template for creation of a probabilistic brain mask and probabilistic tissues priors during longitudinal processing.
95% credible intervals of the region-specific variance ratios are presented for each processing method.
The ANTs SST method dominates the others across the majority of regions-its point estimates (posterior medians) are greater than those of the other processing methods except for the left and right EC values in FreeSurfer Long (although there is significant overlap in the credible intervals in those regions).
These results also suggest that longitudinal processing is to be preferred for both packages.
Box plots showing the distribution of the residual variability, between subject variability, and ratio of the between-subject variability and residual variability for each of the 62 DKT regions.
Note that the "better" measurement maximizes this latter ratio.
3-D volumetric rendering of the regional variance ratio values on the generated ADNI template.
The higher variance ratios indicate greater between-subject to residual variability.
Log-scaled p-values summarizing Tables
95% confidence intervals for the diagnostic contrasts (LMCI-CN, AD-LMCI, AD-CN) of the ADNI-1 data set for each DKT region of the left hemisphere.
Each cell is color-coded based on the adjusted log-scaled p-value significance from dark orange (p<1e-10) to yellow (p=0.1).
Absence of color denotes nonsignificance



Fig. 1 .
Fig. 1.Diagrammatic illustration of the ANTs longitudinal cortical thickness pipeline for a single subject with N time points.
From the N original T1-weighted images (left column, yellow panel) and the group template and priors (bottom row, green panel), the single-subject template (SST), and auxiliary prior images are created (center, blue panel).
These subjectspecific template and other auxiliary images are used to generate the individual time-point cortical thickness maps, in the individual time point's native space (denoted as "ANTs Native" in the text).
Optionally, one can rigidly transform the time-point images prior to segmentation and cortical thickness estimation (right column, red panel).
This alternative processing scheme is referred to as "ANTs SST".
For regional thickness values, regional labels are propagated to each image using a given atlas set (with cortical labels) and joint label fusion.



Fig. 2 .
Fig. 2.



Fig. 3 .
Fig. 3.



Fig. 4 .
Fig. 4.



Fig. 5 .
Fig. 5.



Fig. 6 .
Fig. 6.



Table 2